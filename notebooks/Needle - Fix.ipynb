{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "%pip install rigging tqdm editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# References\n",
    "\n",
    "VULNERABLE_FUNCTION = \"\"\"\\\n",
    "static bool nft_payload_copy_vlan(u32 *d, const struct sk_buff *skb, u8 offset, u8 len)\n",
    "{\n",
    "    int mac_off = skb_mac_header(skb) - skb->data;\n",
    "    u8 *vlanh, *dst_u8 = (u8 *) d;\n",
    "    struct vlan_ethhdr veth;\n",
    "    u8 vlan_hlen = 0;\n",
    "\n",
    "    if ((skb->protocol == htons(ETH_P_8021AD) ||\n",
    "         skb->protocol == htons(ETH_P_8021Q)) &&\n",
    "        offset >= VLAN_ETH_HLEN && offset < VLAN_ETH_HLEN + VLAN_HLEN)\n",
    "        vlan_hlen += VLAN_HLEN;\n",
    "\n",
    "    vlanh = (u8 *) &veth;\n",
    "\n",
    "    if (offset < VLAN_ETH_HLEN + vlan_hlen) {\n",
    "        u8 ethlen = len;\n",
    "\n",
    "        if (vlan_hlen &&\n",
    "            skb_copy_bits(skb, mac_off, &veth, VLAN_ETH_HLEN) < 0)\n",
    "            return false;\n",
    "        else if (!nft_payload_rebuild_vlan_hdr(skb, mac_off, &veth))\n",
    "            return false;\n",
    "\n",
    "        if (offset + len > VLAN_ETH_HLEN + vlan_hlen)\n",
    "            ethlen -= offset + len - VLAN_ETH_HLEN + vlan_hlen;\n",
    "\n",
    "        memcpy(dst_u8, vlanh + offset - vlan_hlen, ethlen);\n",
    "\n",
    "        len -= ethlen;\n",
    "        if (len == 0)\n",
    "            return true;\n",
    "\n",
    "        dst_u8 += ethlen;\n",
    "        offset = ETH_HLEN + vlan_hlen;\n",
    "    } else {\n",
    "        offset -= VLAN_HLEN + vlan_hlen;\n",
    "    }\n",
    "\n",
    "    return skb_copy_bits(skb, offset + mac_off, dst_u8, len) == 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "PATCHED_FUNCTION = \"\"\"\\\n",
    "static bool nft_payload_copy_vlan(u32 *d, const struct sk_buff *skb, u8 offset, u8 len)\n",
    "{\n",
    "    int mac_off = skb_mac_header(skb) - skb->data;\n",
    "    u8 *vlanh, *dst_u8 = (u8 *) d;\n",
    "    struct vlan_ethhdr veth;\n",
    "    u8 vlan_hlen = 0;\n",
    "\n",
    "    if ((skb->protocol == htons(ETH_P_8021AD) ||\n",
    "         skb->protocol == htons(ETH_P_8021Q)) &&\n",
    "        offset >= VLAN_ETH_HLEN && offset < VLAN_ETH_HLEN + VLAN_HLEN)\n",
    "        vlan_hlen += VLAN_HLEN;\n",
    "\n",
    "    vlanh = (u8 *) &veth;\n",
    "\n",
    "    if (offset < VLAN_ETH_HLEN + vlan_hlen) {\n",
    "        u8 ethlen = len;\n",
    "\n",
    "        if (vlan_hlen &&\n",
    "            skb_copy_bits(skb, mac_off, &veth, VLAN_ETH_HLEN) < 0)\n",
    "            return false;\n",
    "        else if (!nft_payload_rebuild_vlan_hdr(skb, mac_off, &veth))\n",
    "            return false;\n",
    "\n",
    "        if (offset + len > VLAN_ETH_HLEN + vlan_hlen)\n",
    "            ethlen -= offset + len - VLAN_ETH_HLEN - vlan_hlen;\n",
    "\n",
    "        memcpy(dst_u8, vlanh + offset - vlan_hlen, ethlen);\n",
    "\n",
    "        len -= ethlen;\n",
    "        if (len == 0)\n",
    "            return true;\n",
    "\n",
    "        dst_u8 += ethlen;\n",
    "        offset = ETH_HLEN + vlan_hlen;\n",
    "    } else {\n",
    "        offset -= VLAN_HLEN + vlan_hlen;\n",
    "    }\n",
    "\n",
    "    return skb_copy_bits(skb, offset + mac_off, dst_u8, len) == 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "VULNERABILITY_DESCRIPTION = \"\"\"\\\n",
    "The vulnerability consists of a stack buffer overflow due to an integer underflow vulnerability inside the nft_payload_copy_vlan function, which is invoked with nft_payload expressions as long as a VLAN tag is present in the current skb. (net/netfilter/nft_payload.c)\n",
    "\n",
    "The initial checks look for a second VLAN tag from the EtherType field and, if the offset falls between the first VLAN_ETH_HLEN bytes and VLAN_ETH_HLEN plus the size of another VLAN header, then nftables should also try and process the second VLAN. The if statement preceeding memcopy correctly checks the boundary of the header using the offset and len variables (8-bit unsigned ints), evaluating to true whenever offset + len exceeds the double-tagged VLAN header. The use of inline statements successfully prevents wrappings because u8 types are automatically promoted before the comparison.\n",
    "\n",
    "However, on the next line, the subtraction does not grant type promotion, and ethlen (u8) may wrap to UINT8_MAX under certain conditions. Some examples of vulnerable offset and len pairs are:\n",
    "\n",
    "offset: 19 & len: 4 & ethlen = 251 offset: 16 & len: 19 & ethlen = 254 offset: 20 & len: 32 & ethlen = 250 ... Other pairs can be listed with the following algorithm:\n",
    "\n",
    "```\n",
    "uint8_t vlan_hlen = VLAN_HLEN, ethlen;\n",
    "for (uint8_t len = 0; len < UINT8_MAX; len++) {\n",
    "    for (uint8_t offset = 0; offset < UINT8_MAX; offset++) {\n",
    "        if (offset < VLAN_ETH_HLEN + vlan_hlen) {\n",
    "            uint8_t ethlen = len;\n",
    "            if (offset + len > VLAN_ETH_HLEN + vlan_hlen) {\n",
    "                ethlen -= offset + len - VLAN_ETH_HLEN + vlan_hlen;\n",
    "                printf(\"offset: %hhu & len: %hhu & ethlen = %hhu\\n\",\n",
    "offset, len, ethlen);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Finally, during the memcpy an up to 255-byte buffer gets copied to the destination register located on the stack, overwriting the adjacent memory. Since we can control the destination register, we can pick NFT_REG32_15 to trigger a 251-byte OOB write on the stack (since NFT_REG32_15 occupies 4 bytes). The vulnerable code path can be reached if the function skb_vlan_tag_present(skb) evaluates to true, that is if the skb->vlan_tci field is set. This is known to happen when the host is placed inside a VLAN, although a modified skb could also be forged manually. (perhaps by forging the packet itself or with some other nft_expr that can edit packets?)\n",
    "\n",
    "The calling function is nft_payload_eval which evaluates the Nftables expression:\n",
    "\n",
    "```\n",
    "void nft_payload_eval(const struct nft_expr *expr,\n",
    "              struct nft_regs *regs,\n",
    "              const struct nft_pktinfo *pkt) {\n",
    "    const struct nft_payload *priv = nft_expr_priv(expr);\n",
    "    const struct sk_buff *skb = pkt->skb;\n",
    "    u32 *dest = &regs->data[priv->dreg]; <===== (0)\n",
    "    int offset;\n",
    "\n",
    "    if (priv->len % NFT_REG32_SIZE)\n",
    "        dest[priv->len / NFT_REG32_SIZE] = 0;\n",
    "\n",
    "    switch (priv->base) {\n",
    "    case NFT_PAYLOAD_LL_HEADER:             <===== (1)\n",
    "        if (!skb_mac_header_was_set(skb))\n",
    "            goto err;\n",
    "\n",
    "        if (skb_vlan_tag_present(skb)) {\n",
    "            if (!nft_payload_copy_vlan(dest, skb,\n",
    "                           priv->offset, priv->len)) <===== (2)\n",
    "                goto err;\n",
    "            return;\n",
    "        }\n",
    "        ...\n",
    "```\n",
    "\n",
    "At (0) dest is set to the chosen destination register, where the payload expression will store its result. If the payload offset base is NFT_PAYLOAD_LL_HEADER (1) and a mac header is present, the vulnerable code path will be taken (2). Furthermore, the kernel must be built with the configuration CONFIG_NETFILTER, CONFIG_NF_TABLES, CONFIG_VLAN_8021Q enabled, and the CAP_NET_ADMIN capability must be enabled, which can be accomplished by entering a new user namespace beforehand.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import litellm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import rigging as rg\n",
    "from rigging.watchers import write_chats_to_jsonl\n",
    "\n",
    "\n",
    "def diff(a: str, b: str, all_lines: bool = True) -> str:\n",
    "    num_lines = max([len(a), len(b)]) if all_lines else 3\n",
    "    diff_gen = difflib.unified_diff(\n",
    "        a.splitlines(True), b.splitlines(True), fromfile=\"before\", tofile=\"after\", n=num_lines\n",
    "    )\n",
    "    return \"\".join(diff_gen)\n",
    "\n",
    "\n",
    "vertex_safety_override = {\n",
    "    \"safety_settings\": [\n",
    "        {\n",
    "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "            \"threshold\": \"BLOCK_ONLY_HIGH\",\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "MODELS = [\n",
    "    rg.get_generator(\"vertex_ai/gemini-1.5-pro-001\", params=rg.GenerateParams(extra=vertex_safety_override)),\n",
    "    rg.get_generator(\"vertex_ai/codechat-bison\", params=rg.GenerateParams(extra=vertex_safety_override)),\n",
    "    \"openai/gpt-4-turbo\",\n",
    "    \"openai/gpt-4o\",\n",
    "    \"anthropic/claude-3-sonnet-20240229\",\n",
    "    \"mistral/mistral-large-latest\",\n",
    "    \"mistral/mistral-medium-latest\",\n",
    "    \"mistral/codestral-latest\",\n",
    "    \"groq/llama3-70b-8192\",\n",
    "]\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are a senior Linux developer who specializes in code security.\n",
    "\"\"\"\n",
    "\n",
    "pipeline = (\n",
    "    rg.get_generator(\"anthropic/claude-3-opus-20240229\")\n",
    "    .chat({\"role\": \"system\", \"content\": SYSTEM_PROMPT})\n",
    "    .catch(litellm.APIError, on_failed=\"skip\")\n",
    ")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Fix:\n",
    "    chat: rg.Chat\n",
    "    fixed_function: str\n",
    "\n",
    "    @property\n",
    "    def diff(self) -> str:\n",
    "        return diff(VULNERABLE_FUNCTION, self.fixed_function)\n",
    "\n",
    "\n",
    "@pipeline.prompt\n",
    "async def fix_code(vulnerable_function: str, vulnerability_description: str) -> Fix:\n",
    "    \"\"\"\n",
    "    Rewrite the source code to fix the vulnerability described.\n",
    "    \"\"\"\n",
    "\n",
    "print(fix_code.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather fixes with reference description\n",
    "\n",
    "ref_fixes: list[Fix] = []\n",
    "for _ in tqdm(range(10)):\n",
    "    ref_fixes.extend(await fix_code.run_over(MODELS, VULNERABLE_FUNCTION, VULNERABILITY_DESCRIPTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ref fixes\n",
    "\n",
    "for fix in ref_fixes:\n",
    "    fix.chat.meta(\n",
    "        diff=fix.diff,\n",
    "        model=fix.chat.generator.model,\n",
    "        used_ref_description=True\n",
    "    )\n",
    "\n",
    "# await write_chats_to_jsonl(\"data/fixes.jsonl\")([f.chat for f in ref_fixes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather model-generated descriptions\n",
    "\n",
    "MAX_MODEL_REFS = 5\n",
    "\n",
    "triage_chats: list[rg.Chat] = []\n",
    "with open(\"triage.jsonl\") as f:\n",
    "    for line in f.readlines():\n",
    "        triage_chats.append(rg.Chat.model_validate_json(line))\n",
    "\n",
    "chats_per_model: dict[str, list[rg.Chat]] = {}\n",
    "for chat in triage_chats:\n",
    "    model = chat.generator.model\n",
    "    chats_per_model.setdefault(model, []).append(chat)\n",
    "\n",
    "longest: dict[str, list[str]] = {}\n",
    "for model, chats in chats_per_model.items():\n",
    "    sorted_chats = sorted(chats, key=lambda chat: len(chat.last.content), reverse=True)\n",
    "    longest[model] = [chat.last.content for chat in sorted_chats][:MAX_MODEL_REFS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fixes with model references\n",
    "\n",
    "import asyncio # noqa: I001\n",
    "\n",
    "\n",
    "model_pipes: list[rg.ChatPipeline] = [pipeline]\n",
    "for model in MODELS:\n",
    "    clone = pipeline.clone()\n",
    "    clone.generator = rg.get_generator(model) if isinstance(model, str) else model\n",
    "    model_pipes.append(clone)\n",
    "\n",
    "model_fixes: list[Fix] = []\n",
    "for i in tqdm(range(MAX_MODEL_REFS)):\n",
    "    descriptions = [longest[pipe.generator.model][i] for pipe in model_pipes]\n",
    "    coros = [pipe.run_prompt(fix_code, VULNERABLE_FUNCTION, description) for pipe, description in zip(model_pipes, descriptions)]\n",
    "    model_fixes.extend(await asyncio.gather(*coros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model-generated fixes\n",
    "\n",
    "for fix in model_fixes:\n",
    "    fix.chat.meta(\n",
    "        diff=fix.diff,\n",
    "        model=fix.chat.generator.model,\n",
    "        used_ref_description=False\n",
    "    )\n",
    "\n",
    "# await write_chats_to_jsonl(\"data/fixes.jsonl\")([f.chat for f in model_fixes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual patch\n",
    "\n",
    "REAL_PATCH = diff(VULNERABLE_FUNCTION, PATCHED_FUNCTION)\n",
    "\n",
    "print(REAL_PATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all chats from disk\n",
    "\n",
    "all_chats: list[rg.Chat] = []\n",
    "\n",
    "with open(\"data/fixes.jsonl\") as f:\n",
    "    for line in f.readlines():\n",
    "        chat = rg.Chat.model_validate_json(line)\n",
    "        chat.last.parts.clear()\n",
    "        all_chats.append(chat)\n",
    "\n",
    "len(all_chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance  # noqa: I001\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Distances:\n",
    "    ref_distances: list[int]\n",
    "    model_distances: list[int]\n",
    "\n",
    "\n",
    "stats: dict[str, Distances] = {}\n",
    "\n",
    "for chat in all_chats:\n",
    "    model = chat.generator.model\n",
    "    if model not in stats:\n",
    "        stats[model] = Distances([], [])\n",
    "\n",
    "    distance = editdistance.eval(REAL_PATCH, chat.metadata[\"diff\"])\n",
    "\n",
    "    if chat.metadata[\"used_ref_description\"]:\n",
    "        stats[model].model_distances.append(distance)\n",
    "    else:\n",
    "        stats[model].ref_distances.append(distance)\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format stats\n",
    "\n",
    "for model, distances in stats.items():\n",
    "    print(model)\n",
    "    if distances.ref_distances:\n",
    "        print(\"Ref:   \", sum(distances.ref_distances) / len(distances.ref_distances))\n",
    "    if distances.model_distances:\n",
    "        print(\"Model: \", sum(distances.model_distances) / len(distances.model_distances))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a random example\n",
    "\n",
    "gen = iter(chat for chat in all_chats if 'gpt-4-' in chat.generator.model)\n",
    "\n",
    "inspect = next(gen)\n",
    "\n",
    "print(inspect.metadata[\"diff\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
